{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZemsO-Sacvg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text\n",
        "from IPython.display import Image\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc, average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OAaTlnvacvh"
      },
      "outputs": [],
      "source": [
        "train = pd.read_excel('lendingclub_traindata.xlsx')\n",
        "validation=pd.read_excel('lendingclub_valdata.xlsx')\n",
        "test=pd.read_excel('lendingclub_testdata.xlsx')\n",
        "# 1 = good, 0 = default\n",
        "print(train.head())\n",
        "print(\"----------------------\")\n",
        "print(validation.head())\n",
        "print(\"----------------------\")\n",
        "print(test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRSI8xhacvi"
      },
      "outputs": [],
      "source": [
        "# remove target column to create feature only dataset\n",
        "X_train = train.drop('loan_status',axis=1)\n",
        "X_val=validation.drop('loan_status',axis=1)\n",
        "X_test=test.drop('loan_status',axis=1)\n",
        "\n",
        "# store target column\n",
        "y_train = train['loan_status']\n",
        "y_val=validation['loan_status']\n",
        "y_test=test['loan_status']\n",
        "\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_val.shape,y_val.shape,X_test.shape,y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A9idDI-acvi"
      },
      "outputs": [],
      "source": [
        "X_train.columns "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N6mHgLZacvj"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(criterion='entropy',max_depth=4,min_samples_split=1000,min_samples_leaf=200,random_state=0)\n",
        "#criterion='entropy': This sets the criterion used by the decision tree algorithm to measure the quality of a split.\n",
        "# max_depth=4: This sets the maximum depth of the decision tree. \n",
        "# min_samples_split: is the minimum number of samples required to split an internal node.\n",
        "# min_samples_leaf: min_samples_leaf is the minimum number of samples required to be in a leaf node.\n",
        "# random_state=0: This sets the random seed used by the random number generator.\n",
        "clf = clf.fit(X_train,y_train)\n",
        "fig, ax = plt.subplots(figsize=(40, 30))\n",
        "# figsize parameter sets the size of the figure in inches.\n",
        "# ax object represents a specific set of axes within the figure.\n",
        "plot_tree(clf, filled=True, feature_names=X_train.columns, proportion=True)\n",
        "#  filled parameter is set to True, which means that the tree nodes will be colored\n",
        "# proportion=True, means that the size of each box in the plot will be proportional to  number of samples that fall into that node.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhTB5oOmacvj"
      },
      "outputs": [],
      "source": [
        "y_train_pred = clf.predict_proba(X_train)\n",
        "y_val_pred=clf.predict_proba(X_val)\n",
        "y_test_pred=clf.predict_proba(X_test)\n",
        "\n",
        "print (y_train_pred)\n",
        "\n",
        "# Calculate maximum likelihood for training set, validation set, and test set\n",
        "\n",
        "mle_vector_train = np.log(np.where(y_train == 1, y_train_pred[:,1], y_train_pred[:,0]))\n",
        "mle_vector_val = np.log(np.where(y_val == 1, y_val_pred[:,1], y_val_pred[:,0]))\n",
        "mle_vector_test = np.log(np.where(y_test == 1, y_test_pred[:,1], y_test_pred[:,0]))\n",
        "\n",
        "# Calculate cost functions from maximum likelihoods\n",
        "\n",
        "cost_function_training=np.negative(np.sum(mle_vector_train)/len(y_train))\n",
        "cost_function_val=np.negative(np.sum(mle_vector_val)/len(y_val))\n",
        "cost_function_test=np.negative(np.sum(mle_vector_test)/len(y_test))\n",
        "\n",
        "print (y_train_pred)\n",
        "\n",
        "\n",
        "print('cost function training set =', cost_function_training)\n",
        "print('cost function validation set =', cost_function_val)\n",
        "print('cost function test set =', cost_function_test)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "PAhVkLuiacvk"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = [.75, .80, .85]\n",
        "results = pd.DataFrame(columns=[\"THRESHOLD\", \"accuracy\", \"true pos rate\", \"true neg rate\", \"false pos rate\", \"precision\", \"f-score\"]) # df to store results\n",
        "results['THRESHOLD'] = THRESHOLD                                                                           # threshold column\n",
        "n_test = len(y_test)\n",
        "Q = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "j = 0                                                                                                      \n",
        "for i in THRESHOLD:    # iterate over each threshold        \n",
        "                         # fit data to model\n",
        "    preds = np.where(Q>i, 1, 0)     # if prob > threshold, predict 1\n",
        "    \n",
        "    cm = (confusion_matrix(y_test, preds,labels=[1, 0], sample_weight=None)/n_test)*100 \n",
        "    # confusion matrix (in percentage)\n",
        "    \n",
        "    print('Confusion matrix for threshold =',i)\n",
        "    print(cm)\n",
        "    print(' ')      \n",
        "    \n",
        "    TP = cm[0][0]                                                                                          # True Positives\n",
        "    FN = cm[0][1]                                                                                          # False Positives\n",
        "    FP = cm[1][0]                                                                                          # True Negatives\n",
        "    TN = cm[1][1]                                                                                          # False Negatives\n",
        "        \n",
        "    results.iloc[j,1] = accuracy_score(y_test, preds) \n",
        "    results.iloc[j,2] = recall_score(y_test, preds)\n",
        "    results.iloc[j,3] = TN/(FP+TN)                                                                         # True negative rate\n",
        "    results.iloc[j,4] = FP/(FP+TN)                                                                         # False positive rate\n",
        "    results.iloc[j,5] = precision_score(y_test, preds)\n",
        "    results.iloc[j,6] = f1_score(y_test, preds)\n",
        "   \n",
        "    j += 1\n",
        "\n",
        "print('ALL METRICS')\n",
        "print(results.T.to_string(header=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_uGboFeacvl"
      },
      "outputs": [],
      "source": [
        "# Compute the ROC curve and AUC\n",
        "fpr, tpr, _ = roc_curve(y_test, Q)\n",
        "roc_auc = auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffdNi14Sacvl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))      # format the plot size\n",
        "lw = 1.5\n",
        "plt.plot(fpr, tpr, color='darkorange', marker='.',\n",
        "         lw=lw, label='Decision Tree (AUC = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--',\n",
        "         label='Random Prediction (AUC = 0.5)' )\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uzN6vBTacvl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}